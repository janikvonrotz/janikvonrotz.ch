---
title: Why I am disappointed in AI
slug: why-i-am-disappointed-in-ai
date: 2025-07-01T08:56:56+02:00
categories:
  - Technology
tags:
  - artifical
  - intelligence
  - large-language-models
  - problems
images:
  - /images/uncanny-valley.png
draft: false
---
I would describe myself as an AI critic. AI as a sales hype has not met any of my expectations. The current state of AI is very disappointing. If you feel the same way and cannot really point out why, this post might be of help.

<!--more-->

So what are my expectations from AI? I discovered 4 essential points:

1. Protection

I hoped that this technology can help solve the problem of spam. Spam is still too prevalent today, one of the biggest problems on the internet. It costs billions in resources to fight spam and causes real harm to real people. My expectation was that AI can help detect spam absolutely accurately.

2. Inclusion

The internet is a great and fun place. But it gets very small if you are handicapped. For blind people, there are not images, only alt texts. I hoped that AI can be a great tool to add alt text to every image there is. Or why not generate videos of people doing sign language to caption another video in real-time? I am pretty sure this technology has the power to include even more people in this endeavor. However, in the current state, it makes the internet a more hostile place.

3. Translation

AI has the power to translate every text into almost any language. However, most often this is a subscription feature. Instead of translating all the texts there are, this powerful tool has become a paid feature to access the world.

4. Machine-Chat

When I am talking with a human, I want to be sure my chat partner is the real person. So why the heck does AI chat pretend to be human? I don't see the point of chatting with a fake human. AI should act like what it is, a statistical model based on a lot of texts.

So, to make this post even more depressing, I'll show you new problems caused by AI:

1. Technical debt at scale

Integrating Large Language Models into Code Editors and calling them AI agents has already become a big business. The promise to software companies is that they get rid of the developers' wages and still do their thing.

In reality, code written, no matter by whom, requires maintenance. Code is infrastructure and contracts between real people. As the environments and requirements change, code needs to be updated, refactored, and fixed. It is constantly changing.

When AI generates more code than can be maintained, systems we trust will fail us.

2. Data harvesting

The AI summaries on top of the Google search results cost Google a fortune. Visitors no longer click on ads. Google is cannibalizing their biggest business! Or are they?

What is more valuable than data about people? The data about interactions between people! And people interacting with an AI that pretends to be human give you exactly this. Google is harvesting interaction data to fuel their ad-tech empire.

3. Near-unsolvable data privacy problems

Getting your data into LLMs is easy. Just publish something on the internet, and the AI crawler next door will feed on it. But have you thought of how data can get out of LLMs? It simply cannot. These LLMs are feeding on it until they explode.

And this fact makes every problem related to data privacy exponentially more difficult to solve.

4. Trust issues

I think this is the most important problem. AI chats pretend to be human. Humans will trust AI chats as if they are human. And this goes well beyond addictive behavior when scrolling through social media feeds. There are people who trust AI more than they can bear. They trust their most intimate problems, thinking they cannot be haunted by computers.

But time and time again, we saw that this kind of trust has failed us. Trusting AI chats will not be different.
